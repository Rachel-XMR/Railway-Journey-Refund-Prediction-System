{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic numerics\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# Graphics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "# Statistical modelling tools\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import spearmanr,chi2_contingency\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report,roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Load data from CSV file\n",
    "df = pd.read_csv('MavenRail.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solve missing values in the dataframe\n",
    "def solve_missing_values(df):\n",
    "    # Delete rows with missing values in 'Departure' and 'Scheduled.Arrival'\n",
    "    df = df[df['Departure'].notnull()]\n",
    "    df = df[df['Scheduled.Arrival'].notnull()]\n",
    "\n",
    "    # Fill missing# define the function to handle the missing values values for 'Railcard' with 'No Railcard'\n",
    "    if 'Railcard' in df.columns and df['Railcard'].isnull().any():\n",
    "        df['Railcard'] = df['Railcard'].fillna('No Railcard')\n",
    "\n",
    "    # Handle missing values in 'Actual.Arrival'\n",
    "    if 'Journey.Status' in df.columns and 'Actual.Arrival' in df.columns:\n",
    "        # Fill with invalid time for 'Cancelled' status\n",
    "        df.loc[df['Journey.Status'] == 'Cancelled', 'Actual.Arrival'] = pd.Timestamp('01/01/1900')\n",
    "\n",
    "        # Fill with 'Scheduled.Arrival' for 'On Time' status\n",
    "        df.loc[\n",
    "            (df['Journey.Status'] == 'On Time') & (df['Actual.Arrival'].isnull()), \n",
    "            'Actual.Arrival'\n",
    "        ] = df['Scheduled.Arrival']\n",
    "\n",
    "    # Fill missing values for 'Reason.for.Delay' with 'No Delay' for 'On Time' status\n",
    "    if 'Journey.Status' in df.columns and 'Reason.for.Delay' in df.columns:\n",
    "        df.loc[df['Journey.Status'] == 'On Time', 'Reason.for.Delay'] = 'No Delay'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the performance of models\n",
    "def evaluate_model(model, X, Y, test_sizes):\n",
    "    #store proportions of each test set\n",
    "    results = []\n",
    "\n",
    "    for test_size in test_sizes:\n",
    "        # Split the dataset\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_proba = model.predict_proba(x_test)[:, 1]  # Probability predictions for AUC\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        auc = roc_auc_score(y_test, y_proba)\n",
    "        \n",
    "        # Append results\n",
    "        results.append({\n",
    "            'test_size': test_size,\n",
    "            'accuracy': accuracy,\n",
    "            'precision_yes': report['1']['precision'],  # Precision for the \"Yes\" class\n",
    "            'recall_yes': report['1']['recall'],        # Recall for the \"Yes\" class\n",
    "            'f1_score_yes': report['1']['f1-score'],   # F1-score for the \"Yes\" class\n",
    "            'auc': auc                                 # AUC score\n",
    "        })\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_data function is used to one-hot encode the specified features and extract the target variable from the given dataframe.\n",
    "def prepare_data(df, features_to_encode, target_variable='Refund.Request'):\n",
    "    # One-hot encode the specified features\n",
    "    X = pd.get_dummies(df[features_to_encode], columns=features_to_encode, drop_first=True)\n",
    "    # Extract the target variable\n",
    "    Y = df[target_variable]\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting confusion matrices with percentages\n",
    "def plot_confusion_matrix(model, x_train, y_train, x_test, y_test, title='Confusion Matrix Visualization with Percentages'):\n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()  # Unpack values\n",
    "    total = np.sum(cm)  # Total number of samples\n",
    "\n",
    "    # Calculate percentages\n",
    "    percentages = [tn / total * 100, fp / total * 100, fn / total * 100, tp / total * 100]\n",
    "\n",
    "    # Plot the confusion matrix with percentages\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "    # Create a color-coded grid for the confusion matrix\n",
    "    categories = ['True Negative', 'False Positive', 'False Negative', 'True Positive']\n",
    "    values = [tn, fp, fn, tp]\n",
    "    colors = ['lightgreen', 'orange', 'pink', 'lightblue']\n",
    "\n",
    "    # Plot the value and category of each element in the confusion matrix\n",
    "    for i, (value, pct, category, color) in enumerate(zip(values, percentages, categories, colors)):\n",
    "        row, col = divmod(i, 2)  # Determine row and column\n",
    "        ax.add_patch(plt.Rectangle((col, row), 1, 1, color=color, alpha=0.7)) # Add a rectangular block\n",
    "        ax.text(\n",
    "            col + 0.5, row + 0.6, f'{category}', ha='center', va='center', fontsize=12 # Display category name\n",
    "        )\n",
    "        ax.text(\n",
    "            col + 0.5, row + 0.4, f'{value} ({pct:.2f}%)', ha='center', va='center', fontsize=12 # Display values and percentages\n",
    "        )\n",
    "\n",
    "    # Adjust plot aesthetics\n",
    "    ax.set_xlim(0, 2) # Limited x-axis range\n",
    "    ax.set_ylim(0, 2) # Limited y-axis range\n",
    "    ax.set_xticks([0.5, 1.5]) # Set the x-axis scale\n",
    "    ax.set_xticklabels(['Predicted Negative', 'Predicted Positive']) # Set the x-axis label\n",
    "    ax.set_yticks([0.5, 1.5]) # Set the y-axis scale\n",
    "    ax.set_yticklabels(['Actual Positive', 'Actual Negative']) # Set the y-axis label\n",
    "    ax.set_xlabel('Prediction') # Set the x-axis title\n",
    "    ax.set_ylabel('Actual') # Set the y-axis title\n",
    "    ax.set_title(title) # Set the graph title\n",
    "    plt.gca().invert_yaxis()  # Flip y-axis to align with traditional confusion matrix view\n",
    "    plt.show()# Display the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the datetime columns to process\n",
    "datetime_columns = ['Departure', 'Scheduled.Arrival', 'Actual.Arrival']\n",
    "\n",
    "# Convert these columns to datetime format\n",
    "for col in datetime_columns:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce') # Convert to datetime64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print metadata information before data cleansing\n",
    "print(\"Metadata Before Cleaning:\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print missing value statistics\n",
    "print(\"\\nMissing value statistics:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values ​​in the dataset\n",
    "df = solve_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print metadata information after data cleansing\n",
    "print(\"Metadata After Cleaning:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing value statistics after cleaning:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chaneg the outlier\n",
    "# Check if Departure is later than Scheduled.Arrival and puls 1 day\n",
    "df.loc[df['Departure'] > df['Scheduled.Arrival'], 'Scheduled.Arrival'] += pd.Timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the number of trips for each route\n",
    "route_num = df.groupby(['Departure.Station', 'Arrival.Station']).size().reset_index(name='Count')\n",
    "# Sort by number of trips from high to low\n",
    "route_num = route_num.sort_values(by='Count', ascending=False)\n",
    "# print result\n",
    "print(\"Number of trips for each route:\")\n",
    "print(route_num) # print top 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of travel time in minutes\n",
    "duration = (df['Actual.Arrival'] - df['Departure']).dt.total_seconds() / 60\n",
    "\n",
    "# Create a new DataFrame containing only the relevant columns\n",
    "duration_df = pd.DataFrame({\n",
    "    'Arrival.Station': df['Arrival.Station'],\n",
    "    'Departure.Station':df['Departure.Station'],\n",
    "    'Trip Duration': duration\n",
    "})\n",
    "\n",
    "# Sort trips by duration in descending order\n",
    "duration_sorted = duration_df.sort_values('Trip Duration', ascending=False)\n",
    "\n",
    "# print result\n",
    "print(duration_sorted.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of travel time in minutes\n",
    "duration = (df['Actual.Arrival'] - df['Departure']).dt.total_seconds() / 60\n",
    "\n",
    "# Create a new DataFrame containing only the relevant columns\n",
    "duration_df = pd.DataFrame({\n",
    "    'Arrival.Station': df['Arrival.Station'],\n",
    "    'Departure.Station': df['Departure.Station'],\n",
    "    'Departure': df['Departure'],\n",
    "    'Actual.Arrival': df['Actual.Arrival'],\n",
    "    'Mean Trip Duration': duration\n",
    "})\n",
    "\n",
    "# Group by unique routes (Departure.Station and Arrival.Station) and calculate the mean duration\n",
    "average_duration = duration_df.groupby(['Departure.Station', 'Arrival.Station'])['Mean Trip Duration'].mean().reset_index()\n",
    "\n",
    "# Sort trips by mean duration in descending order\n",
    "average_duration_sorted = average_duration.sort_values('Mean Trip Duration', ascending=False)\n",
    "\n",
    "# Print the result\n",
    "print(average_duration_sorted.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting price distribution\n",
    "x = df['Price']\n",
    "g=sns.displot( x, kde=True, rug=False)\n",
    "for ax in g.axes.flat:  \n",
    "    ax.legend(labels=[\"KDE\", \"Ticket Price\"])\n",
    "\n",
    "# Set title and axis labels\n",
    "plt.title(\"Price Distribution\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "# Adjust the X-axis range and scale\n",
    "plt.xlim(0, 270)  # Limit the X-axis range to 0 to 270\n",
    "plt.xticks(range(0, 270, 50))  # Set the X-axis tick interval to 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with subplots (3 rows, 2 columns)\n",
    "fig, axes = plt.subplots(3, 2, figsize=(18, 18))\n",
    "\n",
    "# List of variables to plot and corresponding titles\n",
    "variables = ['Journey.Status', 'Payment.Method', 'Ticket.Class', \n",
    "             'Refund.Request','Ticket.Type','Railcard']\n",
    "titles = ['Journey Status Distribution', 'Payment Method Distribution', \n",
    "          'Ticket Class Distribution', 'Refund Request Distribution',\n",
    "          'Ticket Type Distribution','Railcard Distribution' ]\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each variable and create a pie chart\n",
    "for ax, var, title in zip(axes, variables, titles):\n",
    "    # Count the occurrences of each category\n",
    "    counts = df[var].value_counts()\n",
    "    \n",
    "    # Plot the pie chart in percentage\n",
    "    ax.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=90, \n",
    "           colors=sns.color_palette('pastel'), textprops={'fontsize': 19})\n",
    "    # Set sub-figure title\n",
    "    ax.set_title(title, fontsize=20)\n",
    "\n",
    "# Remove unused subplots if the number of variables is less than 6\n",
    "for ax in axes[len(variables):]:\n",
    "    ax.remove()\n",
    "\n",
    "# Adjust sub-graph layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of occurrences of delay reasons\n",
    "delay_reason_counts = df['Reason.for.Delay'].value_counts()\n",
    "\n",
    "# Set the graphics size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Draw horizontal bar graphs\n",
    "delay_reason_counts.plot(kind='barh', color='skyblue', figsize=(12, 8))\n",
    "\n",
    "# Add chart titles and axis labels\n",
    "plt.title('Counts of Delay Reasons', fontsize=16)\n",
    "plt.xlabel('Count', fontsize=14)\n",
    "plt.ylabel('Delay Reason', fontsize=14)\n",
    "# Add grid lines\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout to avoid content overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of occurrences of each departure station\n",
    "departure_counts = df['Departure.Station'].value_counts()\n",
    "# Count the number of occurrences of each arrival station\n",
    "arrival_counts = df['Arrival.Station'].value_counts()\n",
    "\n",
    "# Combine the counts into a single DataFrame\n",
    "combined_counts = pd.DataFrame({\n",
    "    'Departure': departure_counts,\n",
    "    'Arrival': arrival_counts\n",
    "}).fillna(0)  # Fill NaN with 0 for stations that exist only in one category\n",
    "\n",
    "# Sort by the total count (optional, for better visualization)\n",
    "combined_counts['Total'] = combined_counts['Departure'] + combined_counts['Arrival']\n",
    "combined_counts = combined_counts.sort_values('Total', ascending=False).drop(columns=['Total'])\n",
    "\n",
    "# Setting the graphic size\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Draw horizontal bar graphs\n",
    "combined_counts.plot(kind='barh', stacked=False, figsize=(14, 10), color=['skyblue', 'orange'])\n",
    "\n",
    "# Add chart titles and axis labels\n",
    "plt.title('Counts of Departure and Arrival Stations', fontsize=16)\n",
    "plt.xlabel('Count', fontsize=14)\n",
    "plt.ylabel('Station', fontsize=14)\n",
    "# Add a legend\n",
    "plt.legend(title=\"Category\", fontsize=12)\n",
    "# Add gridlines\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "#  Adjust the layout to avoid overlapping content\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display statistical summary for 'Price'\n",
    "print(\"\\nStatistics of Price:\")\n",
    "print(df['Price'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 'Yes'/'No' to 1/0 for Refund.Request\n",
    "df['Refund.Request'] = df['Refund.Request'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Iterate over the specified columns and calculate the mean Refund.Request\n",
    "for i in ['Payment.Method', 'Railcard', 'Ticket.Class', 'Ticket.Type',  \n",
    "          'Departure.Station', 'Arrival.Station', 'Journey.Status', 'Reason.for.Delay',\n",
    "          'Price','Departure', 'Scheduled.Arrival', 'Actual.Arrival']:\n",
    "    # Group by current column (i) and calculate the mean value of 'Refund.Request'\n",
    "    print((df[[i, 'Refund.Request']].groupby(i, as_index=False).mean().sort_values(by='Refund.Request', ascending=False)).head(5))\n",
    "    print('-'*10,'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate delay time\n",
    "delay_time = (df['Actual.Arrival'] - df['Departure'])\n",
    "# Convert delay time to minutes and add to new column 'DelayInMinutes'\n",
    "df['DelayInMinutes'] = delay_time.dt.total_seconds() / 60\n",
    "# Replace non-positive delay times with NaN\n",
    "df['DelayInMinutes'] = df['DelayInMinutes'].where(df['DelayInMinutes']>0,np.nan)\n",
    "# Print the delay time column after processing\n",
    "print(\"\\nDelay time in minutes：\")\n",
    "print(df[['Scheduled.Arrival', 'Actual.Arrival', 'DelayInMinutes']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of NaN values in DelayInMinutes\n",
    "nan_count = df['DelayInMinutes'].isnull().sum()\n",
    "print(\"Number of NaN values in DelayInMinutes:\", nan_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column MediumPrice to mark if the ticket price is in the range (10 < Price <= 30)\n",
    "df['MediumPrice'] = np.where((df['Price'] > 10) & (df['Price'] <= 30), 1, 0)\n",
    "\n",
    "# Filter Journey.Status is not \"On Time\"\n",
    "filtered_df = df[df['Journey.Status'] != 'On Time'].copy()\n",
    "\n",
    "# Prepare data for logistic regression\n",
    "X = filtered_df[['MediumPrice']]\n",
    "Y = filtered_df['Refund.Request']\n",
    "\n",
    "# Split data into train and test sets (80% for training, 20% for test)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use logistic regression model to train data\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Predict the target variable on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# MediumPrice regression coefficients\n",
    "beta1 = model.coef_[0][0]\n",
    "print(\"Coefficient of MediumPrice:\", beta1)\n",
    "\n",
    "# Intercept of the model\n",
    "beta0 = model.intercept_\n",
    "print(\"Intercept:\", beta0)\n",
    "\n",
    "# Calculate the probability of a refund for a given fare\n",
    "input_5 = pd.DataFrame([[0]], columns=['MediumPrice'])  # £5 (out of range)\n",
    "input_25 = pd.DataFrame([[1]], columns=['MediumPrice'])  # £25 (in range)\n",
    "\n",
    "# Use the model to predict probabilities\n",
    "prob_5 = model.predict_proba(input_5)[0][1]\n",
    "prob_25 = model.predict_proba(input_25)[0][1]\n",
    "\n",
    "# Print the refund probability for a given ticket price\n",
    "print(f\"Probability of requesting a refund for £5 ticket: {prob_5:.2%}\")\n",
    "print(f\"Probability of requesting a refund for £25 ticket: {prob_25:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV file\n",
    "predicted = pd.read_csv('ToPredict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print missing values\n",
    "print(\"\\nMissing value statistics:\")\n",
    "print(predicted.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use previously defined functions to handle missing values\n",
    "predicted = solve_missing_values(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print missing value statistics after cleaning\n",
    "print(\"\\nMissing value statistics after washing:\")\n",
    "print(predicted.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numeric and categorical variables\n",
    "numeric_vars = df.select_dtypes(include=['int64']).columns\n",
    "categorical_vars = df.select_dtypes(include=['object','datetime64[ns]','float64']).columns\n",
    "\n",
    "# Initialisation result storage\n",
    "spearman_results = [] # Storage Spearman correlation analysis results\n",
    "chi_square_results = [] # Stored chi-square test results\n",
    "\n",
    "# Calculate Spearman's correlation for numerical variables\n",
    "for var in numeric_vars:\n",
    "    if var != 'Refund.Request':  # Exclude the target variable itself\n",
    "        correlation, p_value = spearmanr(df[var], df['Refund.Request'])\n",
    "        spearman_results.append((var, correlation, p_value))\n",
    "\n",
    "# Print Spearman correlation analysis results\n",
    "print(\"Spearman correlation results (sorted by p-value):\")\n",
    "for var, correlation, p_value in spearman_results:\n",
    "    print(f\"{var}: correlation={correlation:.4f}, p-value={p_value:.4f}\")\n",
    "\n",
    "# Calculate Chi-square test for categorical variables\n",
    "for var in categorical_vars:\n",
    "    if var != 'Refund.Request':  # Exclude the target variable itself\n",
    "        contingency_table = pd.crosstab(df[var], df['Refund.Request'])\n",
    "        chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "        chi_square_results.append((var, chi2,p))\n",
    "\n",
    "# Sort results by chi-square value in ascending ascending\n",
    "chi_square_results = sorted(chi_square_results, key=lambda x: x[1])\n",
    "\n",
    "# Print chi-square test results\n",
    "print(\"\\nChi-square test results (sorted by p-value):\")\n",
    "for var,chi2, p in chi_square_results:\n",
    "    print(f\"{var}: Chi-square = {chi2:.4f}, p-value={p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature columns to be used in the model\n",
    "features = ['Payment.Method', 'DelayInMinutes', 'Journey.Status', \n",
    "            'Reason.for.Delay', 'Departure.Station', 'Arrival.Station']\n",
    "#Returns the feature matrix X and the target variable Y\n",
    "X, Y = prepare_data(df, features, 'Refund.Request')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the random forest model\n",
    "random_forest_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "\n",
    "# Define the test set ratio list\n",
    "test_sizes = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "# Evaluating the Random Forest Model\n",
    "results_rf_x1 = evaluate_model(random_forest_model, X, Y, test_sizes)\n",
    "\n",
    "# Printing evaluation results\n",
    "print(\"Random Forest(Base Features):\")\n",
    "print(results_rf_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define the random forest mode\n",
    "random_forest_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "\n",
    "# Call the function that draws the confusion matrix\n",
    "plot_confusion_matrix(random_forest_model, x_train1, y_train1, x_test1, y_test1, \n",
    "                      title='Random Forest Confusion Matrix,test size=0.25')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the logistic regression model\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Define the test set ratio list\n",
    "test_sizes = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "\n",
    "# Evaluation of logistic regression models\n",
    "results_logistic = evaluate_model(logistic_model, X, Y, test_sizes)\n",
    "\n",
    "# Printing evaluation results\n",
    "print(\"Logistic Regression (Base Features):\")\n",
    "print(results_logistic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression with Ticket.Type feature\n",
    "# Data preparation: add `Ticket.Type` feature\n",
    "features2 = ['Payment.Method', 'DelayInMinutes', 'Journey.Status', \n",
    "             'Reason.for.Delay', 'Departure.Station', 'Arrival.Station', 'Ticket.Type']\n",
    "#Generate feature matrix X2 and target variable Y\n",
    "X2, Y2 = prepare_data(df, features2,'Refund.Request')\n",
    "\n",
    "# Defining a logistic regression model\n",
    "logistic_model2 = LogisticRegression(random_state=42)\n",
    "\n",
    "# Evaluating Logistic Regression Model Performance\n",
    "results_logistic_x2 = evaluate_model(logistic_model2, X2, Y2, test_sizes)\n",
    "\n",
    "# Printing evaluation results\n",
    "print(\"Logistic Regression (Features with Ticket.Type):\")\n",
    "print(results_logistic_x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation: Add `Price` feature\n",
    "features3 = ['Payment.Method', 'DelayInMinutes', 'Journey.Status', \n",
    "             'Reason.for.Delay', 'Departure.Station', 'Arrival.Station','Price']\n",
    "X3, Y3 = prepare_data(df, features3,'Refund.Request')\n",
    "\n",
    "# Generate feature matrix X3 and target variable Y\n",
    "logistic_model3 = LogisticRegression(random_state=42)\n",
    "\n",
    "# Defining a logistic regression model\n",
    "results_logistic_x3 = evaluate_model(logistic_model3, X3, Y3, test_sizes)\n",
    "\n",
    "# Printing evaluation results\n",
    "print(\"Logistic Regression (Features with Price):\")\n",
    "print(results_logistic_x3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data partitioning: Divide the data into training set and test set\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define the logistic regression model\n",
    "logistic_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Call the function to draw the confusion matrix\n",
    "plot_confusion_matrix(logistic_model, x_train2, y_train2, x_test2, y_test2, \n",
    "                      title='Logistic Regression Confusion Matrix,test size=0.25')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Scheduled.Arrival' and 'Actual.Arrival' to date and time format\n",
    "predicted['Scheduled.Arrival'] = pd.to_datetime(predicted['Scheduled.Arrival'], errors='coerce')\n",
    "predicted['Actual.Arrival'] = pd.to_datetime(predicted['Actual.Arrival'], errors='coerce')\n",
    "\n",
    "# Fill missing values ​​in the 'Railcard' column with 'No Railcard'\n",
    "predicted['Railcard'] = predicted['Railcard'].fillna('No Railcard')\n",
    "\n",
    "#Solve the missing values in the 'Actual.Arrival'\n",
    "# Handle 'Cancelled' trips\n",
    "predicted.loc[predicted['Journey.Status'] == 'Cancelled', 'Actual.Arrival'] = pd.NaT\n",
    "# Handle 'On Time' journeys\n",
    "predicted.loc[\n",
    "    (predicted['Journey.Status'] == 'On Time') & (predicted['Actual.Arrival'].isnull()),\n",
    "    'Actual.Arrival'\n",
    "] = predicted['Scheduled.Arrival']\n",
    "\n",
    "# Set Reason.for.Delay to 'No Delay' for 'On Time' journeys\n",
    "predicted.loc[predicted['Journey.Status'] == 'On Time', 'Reason.for.Delay'] = 'No Delay'\n",
    "\n",
    "# Add DelayInMinutes column\n",
    "predicted['DelayInMinutes'] = (predicted['Actual.Arrival'] - predicted['Scheduled.Arrival']).dt.total_seconds() / 60\n",
    "# Fill missing or NaN delay times with 0\n",
    "predicted['DelayInMinutes'] = predicted['DelayInMinutes'].fillna(0)\n",
    "\n",
    "# One-hot encode 'predicted' data\n",
    "predicted_encoded = pd.get_dummies(predicted, columns=[\n",
    "    'Payment.Method', 'Journey.Status', 'Reason.for.Delay', \n",
    "    'Departure.Station', 'Arrival.Station','DelayInMinutes'\n",
    "], drop_first=True)\n",
    "\n",
    "# Align 'predicted' data with training data\n",
    "predicted_encoded = predicted_encoded.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# Make predictions using the logistic regression model\n",
    "logistic_predictions = logistic_model.predict(predicted_encoded)\n",
    "\n",
    "# Convert predictions to probabilities\n",
    "logistic_probabilities = logistic_model.predict_proba(predicted_encoded)[:, 1]\n",
    "\n",
    "# Add predictions and probabilities to the original DataFrame\n",
    "predicted['Logistic_Predictions'] = logistic_predictions\n",
    "predicted['Logistic_Probabilities'] = logistic_probabilities\n",
    "\n",
    "# Print results\n",
    "print(predicted[['Payment.Method', 'Journey.Status', 'Reason.for.Delay', \n",
    "                 'Departure.Station', 'Arrival.Station', 'DelayInMinutes',\n",
    "                 'Logistic_Predictions','Logistic_Probabilities']])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
